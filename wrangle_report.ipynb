{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6077d2b",
   "metadata": {},
   "source": [
    "The dataset analyzed in this project was the tweet archive of WeRateDogs. The data gathering process involved directly downloading the archive tweets file provided via link by Udacity in CSV format, programmatically downloading the image prediction files hosted on Udacity servers and gathering additional data such as retweet and favorite counts using twitter API and python tweepy package.\n",
    "After loading the gathered data into 3 DataFrames on pandas, It was observed visually on pandas and excel, and programmatically for data quality and tidiness. 10 quality and 3 tidiness issues were identified. Below are the issues identified and the steps taken to clean them:\n",
    "\n",
    "#### Quality Issues\n",
    "#### Issue - Missing values in dog name and dog stage (can't clean)\n",
    "#### Issue - Inaccurate representation of missing values in dog name and dog ‘stages’\n",
    "**Solution** - pandas `replace` function was used to replace missing values represented by None with the standard `np.nan` used in python to indicate missing values.\n",
    "\n",
    "#### Issue - Incorrect dog names\n",
    "**Solution** - Through visual assessment of the data, it was discovered that all actual names started with upper case.  Based on this, code was used to iterate through the names column and a list of all names starting with lower case (i.e., likely incorrect names) was created. Through visual assessment, incorrect names in rows with actual names were identified and corrected while those that don’t have actual names were replaced with np.nan.\n",
    "\n",
    "#### Issue – Inaccurate values in ratings\n",
    "**Solution** – Visual assessment was used to compare text and ratings. Identified wrong ratings was replaced with the correct values.\n",
    "\n",
    "#### Issue – Only Original tweets required\n",
    "**Solution** – all retweets rows were selected are dropped using pandas `loc` and `drop` functions. Pandas `isin` function was used to check for original tweets with image predictions in table 2 and these were used to update the DataFrame.\n",
    "\n",
    "#### Issue – Invalid datatypes\n",
    "**Solution** – The data types of tweet id in tables 1, 2 and 3, were converted from integer to string using pandas `astype` function. \n",
    "The timestamp in table 1 was converted from string to datetime using pandas `to_datetime` function.\n",
    "\n",
    "#### Issue – inconsistent column name – table 3 \n",
    "**Solution** – The id column of table 3 which contains tweet ids’ was renamed to tweet_id.\n",
    "\n",
    "\n",
    "#### Tidiness Issues\n",
    "#### Issue – column headers are values, not variable names\n",
    "**Solution** – The columns doggo, floofer, puppo and pupper were melted into 2 separate DataFrames using pandas `melt` function with `vars_name=’dog_stage’` passed as argument. The separated DataFrames were filtered to contain only rows with actual values (i.e., non nan) in the above columns, and these were concatenated using pandas `concat` function. The new DataFrame was then merged to table 1 using left join on tweet id. Finally, the columns doggo, floofer, puppo and pupper was dropped from table 1.\n",
    "\n",
    "#### Issue – multiple variables (text and url) was stored in one column (text)\n",
    "**Solution** – The url was extracted from the text column and stored in a different column called ‘tweet_url’. Then the text column was split into two part using ‘https’ as delimiter and only the first part, which contains only text, was selected and stored in text column.\n",
    "\n",
    "\n",
    "#### Issue – Merge twitter archive, additional data and image prediction table into a single table\n",
    "**Solution** – The twitter archive table and additional data table was merged as a single table named df_master. Then df_master was merged with image prediction table.  The pandas `merge` function was used in both cases using tweet_id as label to join on.\n",
    "\n",
    "\n",
    "The final cleaned data with 2005 rows and 25 columns, was saved as a CSV file named \"twitter_archive_master.csv\" using pandas `to_csv function` with \"index=False\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
